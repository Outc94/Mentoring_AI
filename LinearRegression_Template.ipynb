{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression_Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYvTpoUY7A2OVcl3IuQd5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Outc94/Mentoring_AI/blob/main/LinearRegression_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEvpqisbKNlD"
      },
      "source": [
        "class ScratchLinearRegression():\n",
        "\n",
        "    def __init__(self, num_iter=1000, lr=0.01, no_bias=False, verbose=False):\n",
        "        # ハイパーパラメータを属性として記録する\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        \n",
        "        # 損失を記録するための配列を用意する\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "        \n",
        "    def _linear_hypothesis(self,X):\n",
        "\n",
        "        x1 = X\n",
        "        \n",
        "        # x0 バイアス項の作成\n",
        "        if self.no_bias == True:\n",
        "            x0 = np.zeros(x1.shape[0])\n",
        "        else:\n",
        "            x0 = np.ones(x1.shape[0])\n",
        "    \n",
        "        return np.concatenate([x0.reshape(-1,1),x1],axis=1)\n",
        "    \n",
        "    \n",
        "    def _gradient_descent(self, X, error):\n",
        "\n",
        "        self.theta = self.theta - self.lr*np.dot(error,X)/len(X)\n",
        "    \n",
        "        \n",
        "    def fit(self, X, y, X_val=False, y_val=False):\n",
        "\n",
        "        x1 = self._linear_hypothesis(X)\n",
        "        \n",
        "        # パラメータθの初期値を乱数で与える。\n",
        "        self.theta = np.random.random(x1.shape[1])\n",
        "        \n",
        "        for i in range(self.iter):\n",
        "            \n",
        "            # 仮想関数による予測値の計算\n",
        "            y1 = np.dot(x1,self.theta)\n",
        "            \n",
        "            # 真の値と予測値の誤差を計算する\n",
        "            error = y1 - y\n",
        "            self.loss[i] += np.mean(error**2)/2\n",
        "            \n",
        "            # X_validが入力された場合、x2と読み替えられます。\n",
        "            if (type(X_val) != bool):\n",
        "                x2 = self._linear_hypothesis(X_val)\n",
        "                y2 = np.dot(x2,self.theta)\n",
        "                \n",
        "                error_val = y2 - y_val\n",
        "                self.val_loss[i] += np.mean(error_val**2)/2 \n",
        "            \n",
        "            # パラメータθを最急降下法で最適化する。\n",
        "            self._gradient_descent(x1, error)\n",
        "            \n",
        "            if self.verbose:\n",
        "            # verboseがtrueに設定されている場合、学習プロセスを出力します。\n",
        "                print('n_iter:', i,\n",
        "                      'loss:',self.loss[i],\n",
        "                      'theta:',self.theta)\n",
        "                \n",
        "                \n",
        "    def predict(self, X):\n",
        "\n",
        "        return np.dot(self._linear_hypothesis(X),self.theta)"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}